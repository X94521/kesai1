{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import missingno as msno\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import sparse\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% \n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train=pd.read_csv(r'C:\\Users\\Lenovo\\Desktop\\kesai\\train_set.csv',na_values=[-1, \"unknown\"])\n",
    "test =pd.read_csv(r'C:\\Users\\Lenovo\\Desktop\\kesai\\test_set.csv',na_values=[-1, \"unknown\"])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "#把列分为类别列，bin列和连续值列\n",
    "bincol = [\"default\", \"housing\", \"loan\"]\n",
    "catcol = [\"marital\", \"education\", \"contact\", \"poutcome\", \"job\"]\n",
    "othercol = ['age', 'balance', 'day', 'month', 'duration', 'campaign', 'pdays', 'previous']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def rename_col(st):\n",
    "    if st in bincol:\n",
    "        return st+\"_bin\"\n",
    "    elif st in catcol:\n",
    "        return st + \"_cat\"\n",
    "    else:\n",
    "        return st\n",
    "\n",
    "train.columns = train.columns.map(lambda x:rename_col(x))\n",
    "test.columns = test.columns.map(lambda x:rename_col(x))\n",
    "bincol = list(map(lambda x: x+\"_bin\", bincol))\n",
    "catcol = list(map(lambda x: x+\"_cat\", catcol))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "misssing_col = train.isnull().any()[train.isnull().any()]\n",
    "col_missing = train.isnull().any()[train.isnull().any()].index\n",
    "miss_cat = [x for x in col_missing if x in catcol] + [\"pdays\"]\n",
    "train[miss_cat] = train[miss_cat].replace(np.nan, -1)\n",
    "test[miss_cat] = test[miss_cat].replace(np.nan, -1)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "len_train = len(train)\n",
    "len_test = len(test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "miss_nocat = [x for x in col_missing if x not in miss_cat]\n",
    "train['pdays_miss'] = np.zeros(len_train)\n",
    "train['pdays_miss'] [train.pdays.isnull()] = 1\n",
    "test['pdays_miss'] = np.zeros(len_test)\n",
    "test['pdays_miss'] [test.pdays.isnull()] = 1\n",
    "train[miss_nocat] = train[miss_nocat].replace(np.nan,train[miss_nocat].median())\n",
    "test[miss_nocat] = test[miss_nocat].replace(np.nan, train[miss_nocat].median())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "poutcome_mapping = {-1:-1,\"other\":0,\"success\":1,\"failure\":-2}\n",
    "train[\"poutcome_cat\"] = train[\"poutcome_cat\"].map(poutcome_mapping)\n",
    "train[\"poutcome_pdays\"] = train[\"poutcome_cat\"] * train[\"pdays\"]\n",
    "test[\"poutcome_cat\"] = test[\"poutcome_cat\"].map(poutcome_mapping)\n",
    "test[\"poutcome_pdays\"] = test[\"poutcome_cat\"] * test[\"pdays\"]\n",
    "for i in bincol:\n",
    "    bin_mapping = {\"yes\":1, \"no\":0}\n",
    "    train[i] = train[i].map(bin_mapping)\n",
    "    test[i] = test[i].map(bin_mapping)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Index([], dtype='object')",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "Index([], dtype='object')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 10
    }
   ],
   "source": [
    "print(train.isnull().any()[train.isnull().any()].index)\n",
    "test.isnull().any()[test.isnull().any()].index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['y'], dtype='object')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 11
    }
   ],
   "source": [
    "data = pd.concat([train,test])\n",
    "feature=data.columns.tolist()\n",
    "data.isnull().any()[data.isnull().any()].index\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "feature.remove('ID')\n",
    "feature.remove('y')\n",
    "sparse_feature= ['contact_cat','default_bin','education_cat','housing_bin','job_cat','loan_bin','marital_cat','month','poutcome_cat']\n",
    "dense_feature=list(set(feature)-set(sparse_feature))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "def get_new_columns(name,aggs):\n",
    "    l=[]\n",
    "    for k in aggs.keys():\n",
    "        for agg in aggs[k]:\n",
    "            if str(type(agg))==\"<class 'function'>\":\n",
    "                l.append(name + '_' + k + '_' + 'other')\n",
    "            else:\n",
    "                l.append(name + '_' + k + '_' + agg)\n",
    "    return l\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stderr",
     "text": [
      "\r  0%|                                                                                            | 0/9 [00:00<?, ?it/s]",
      "\r 11%|█████████▎                                                                          | 1/9 [00:00<00:01,  4.87it/s]",
      "\r 22%|██████████████████▋                                                                 | 2/9 [00:00<00:01,  4.14it/s]",
      "\r 33%|████████████████████████████                                                        | 3/9 [00:01<00:01,  3.01it/s]",
      "\r 44%|█████████████████████████████████████▎                                              | 4/9 [00:01<00:02,  2.04it/s]",
      "\r 56%|██████████████████████████████████████████████▋                                     | 5/9 [00:03<00:02,  1.40it/s]",
      "\r 67%|████████████████████████████████████████████████████████                            | 6/9 [00:04<00:03,  1.03s/it]",
      "\r 78%|█████████████████████████████████████████████████████████████████▎                  | 7/9 [00:07<00:02,  1.41s/it]",
      "\r 89%|██████████████████████████████████████████████████████████████████████████▋         | 8/9 [00:10<00:01,  1.90s/it]",
      "\r100%|████████████████████████████████████████████████████████████████████████████████████| 9/9 [00:14<00:00,  2.46s/it]",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "for d in tqdm(sparse_feature):\n",
    "    aggs={}\n",
    "    for s in sparse_feature:\n",
    "        aggs[s]=['count','nunique']\n",
    "    for den in dense_feature:\n",
    "        aggs[den]=['mean','max','min','std']\n",
    "    aggs.pop(d)\n",
    "    temp=data.groupby(d).agg(aggs).reset_index()\n",
    "    temp.columns=[d]+get_new_columns(d,aggs)\n",
    "    data=pd.merge(data,temp,on=d,how='left')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%特征组合\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "Index(['y'], dtype='object')"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 15
    }
   ],
   "source": [
    "data.isnull().any()[data.isnull().any()].index"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "for s in catcol:\n",
    "    data=pd.concat([data,pd.get_dummies(data[s],prefix=s+'_')],axis=1)\n",
    "    data.drop(s,axis=1,inplace=True)\n",
    "# 月份编码\n",
    "data=pd.concat([data,pd.get_dummies(data[\"month\"],prefix=\"month\"+'_')],axis=1)\n",
    "data.drop(\"month\",axis=1,inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%编码\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "df_train=data[data['y'].notnull()]\n",
    "df_test=data[data['y'].isnull()]\n",
    "\n",
    "target=df_train['y']\n",
    "df_train_columns=df_train.columns.tolist()\n",
    "df_train_columns.remove('ID')\n",
    "df_train_columns.remove('y')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "df_train.head()\n",
    "feature=df_train.columns.tolist()\n",
    "feature.remove(\"ID\")\n",
    "feature.remove('y')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train[feature], df_train.y, train_size = 0.25, random_state = 33)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits",
      "\n",
      "Top N Features Best RF Params:{'max_depth': 20, 'min_samples_split': 3, 'n_estimators': 500}",
      "\n",
      "Top N Features Best RF Score:0.89362878698108",
      "\n",
      "Top N Features RF Train Score:0.9729430817237429",
      "\n",
      "Sample 10 Features from RF Classifier",
      "\n",
      "5                              duration\n1                               balance\n3                                   day\n0                                   age\n2                              campaign\n10                       poutcome_pdays\n8                                 pdays\n432    poutcome_cat_education_cat_count\n11                             previous\n436          poutcome_cat_job_cat_count\nName: feature, dtype: object",
      "\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits",
      "\n",
      "Top N Features Best Ada Params:{'learning_rate': 0.1, 'n_estimators': 500}",
      "\n",
      "Top N Features Best Ada Score:0.9027925899593159",
      "\n",
      "Top N Features Ada Train Score:0.904175060236205",
      "\n",
      "Sample 10 Feature from Ada Classifier:",
      "\n",
      "5            duration\n3                 day\n8               pdays\n0                 age\n2            campaign\n1             balance\n10     poutcome_pdays\n11           previous\n393     month_age_max\n404    month_day_mean\nName: feature, dtype: object",
      "\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits",
      "\n",
      "Top N Features Best ET Params:{'max_depth': 20, 'min_samples_split': 4, 'n_estimators': 500}",
      "\n",
      "Top N Features Best ET Score:0.8858869534305013",
      "\n",
      "Top N Features ET Train Score:0.9554844570841727",
      "\n",
      "Sample 10 Features from ET Classifier:",
      "\n",
      "5                             duration\n3                                  day\n0                                  age\n1                              balance\n2                             campaign\n469    poutcome_cat_poutcome_pdays_max\n493                    poutcome_cat__1\n447               poutcome_cat_age_std\n476          poutcome_cat_balance_mean\n444              poutcome_cat_age_mean\nName: feature, dtype: object",
      "\n",
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits",
      "\n"
     ],
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=25)]: Using backend LokyBackend with 25 concurrent workers.\n",
      "[Parallel(n_jobs=25)]: Done  13 out of  20 | elapsed:  4.2min remaining:  2.2min\n",
      "[Parallel(n_jobs=25)]: Done  20 out of  20 | elapsed:  4.2min finished\n",
      "[Parallel(n_jobs=25)]: Using backend LokyBackend with 25 concurrent workers.\n",
      "[Parallel(n_jobs=25)]: Done  13 out of  20 | elapsed:  9.6min remaining:  5.1min\n",
      "[Parallel(n_jobs=25)]: Done  20 out of  20 | elapsed:  9.7min finished\n",
      "[Parallel(n_jobs=25)]: Using backend LokyBackend with 25 concurrent workers.\n",
      "[Parallel(n_jobs=25)]: Done  13 out of  20 | elapsed:  7.0min remaining:  3.8min\n",
      "[Parallel(n_jobs=25)]: Done  20 out of  20 | elapsed:  7.2min finished\n",
      "[Parallel(n_jobs=25)]: Using backend LokyBackend with 25 concurrent workers.\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "no_features = [\"y\", \"ID\"]\n",
    "features = df_train[[x for x in df_train.columns if x not in no_features]].columns[:]\n",
    "len(features)\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import model_selection\n",
    "\n",
    "def get_top_n_features(train_data_X, train_data_Y, top_n_features):\n",
    "\n",
    "    # random forest\n",
    "    rf_est = RandomForestClassifier(random_state=0)\n",
    "    rf_param_grid = {'n_estimators': [500], 'min_samples_split': [2, 3], 'max_depth': [20]}\n",
    "    rf_grid = model_selection.GridSearchCV(rf_est, rf_param_grid, n_jobs=25, cv=10, verbose=1)\n",
    "    rf_grid.fit(train_data_X, train_data_Y)\n",
    "    print('Top N Features Best RF Params:' + str(rf_grid.best_params_))\n",
    "    print('Top N Features Best RF Score:' + str(rf_grid.best_score_))\n",
    "    print('Top N Features RF Train Score:' + str(rf_grid.score(train_data_X, train_data_Y)))\n",
    "    feature_imp_sorted_rf = pd.DataFrame({'feature': list(train_data_X),\n",
    "                                          'importance': rf_grid.best_estimator_.feature_importances_}).sort_values('importance', ascending=False)\n",
    "    features_top_n_rf = feature_imp_sorted_rf.head(top_n_features)['feature']\n",
    "    print('Sample 10 Features from RF Classifier')\n",
    "    print(str(features_top_n_rf[:10]))\n",
    "\n",
    "    # AdaBoost\n",
    "    ada_est =AdaBoostClassifier(random_state=0)\n",
    "    ada_param_grid = {'n_estimators': [500], 'learning_rate': [0.01, 0.1]}\n",
    "    ada_grid = model_selection.GridSearchCV(ada_est, ada_param_grid, n_jobs=25, cv=10, verbose=1)\n",
    "    ada_grid.fit(train_data_X, train_data_Y)\n",
    "    print('Top N Features Best Ada Params:' + str(ada_grid.best_params_))\n",
    "    print('Top N Features Best Ada Score:' + str(ada_grid.best_score_))\n",
    "    print('Top N Features Ada Train Score:' + str(ada_grid.score(train_data_X, train_data_Y)))\n",
    "    feature_imp_sorted_ada = pd.DataFrame({'feature': list(train_data_X),\n",
    "                                           'importance': ada_grid.best_estimator_.feature_importances_}).sort_values('importance', ascending=False)\n",
    "    features_top_n_ada = feature_imp_sorted_ada.head(top_n_features)['feature']\n",
    "    print('Sample 10 Feature from Ada Classifier:')\n",
    "    print(str(features_top_n_ada[:10]))\n",
    "\n",
    "    # ExtraTree\n",
    "    et_est = ExtraTreesClassifier(random_state=0)\n",
    "    et_param_grid = {'n_estimators': [500], 'min_samples_split': [3, 4], 'max_depth': [20]}\n",
    "    et_grid = model_selection.GridSearchCV(et_est, et_param_grid, n_jobs=25, cv=10, verbose=1)\n",
    "    et_grid.fit(train_data_X, train_data_Y)\n",
    "    print('Top N Features Best ET Params:' + str(et_grid.best_params_))\n",
    "    print('Top N Features Best ET Score:' + str(et_grid.best_score_))\n",
    "    print('Top N Features ET Train Score:' + str(et_grid.score(train_data_X, train_data_Y)))\n",
    "    feature_imp_sorted_et = pd.DataFrame({'feature': list(train_data_X),\n",
    "                                          'importance': et_grid.best_estimator_.feature_importances_}).sort_values('importance', ascending=False)\n",
    "    features_top_n_et = feature_imp_sorted_et.head(top_n_features)['feature']\n",
    "    print('Sample 10 Features from ET Classifier:')\n",
    "    print(str(features_top_n_et[:10]))\n",
    "    \n",
    "    # GradientBoosting\n",
    "    gb_est =GradientBoostingClassifier(random_state=0)\n",
    "    gb_param_grid = {'n_estimators': [500], 'learning_rate': [0.01, 0.1], 'max_depth': [20]}\n",
    "    gb_grid = model_selection.GridSearchCV(gb_est, gb_param_grid, n_jobs=25, cv=10, verbose=1)\n",
    "    gb_grid.fit(train_data_X, train_data_Y)\n",
    "    print('Top N Features Best GB Params:' + str(gb_grid.best_params_))\n",
    "    print('Top N Features Best GB Score:' + str(gb_grid.best_score_))\n",
    "    print('Top N Features GB Train Score:' + str(gb_grid.score(train_data_X, train_data_Y)))\n",
    "    feature_imp_sorted_gb = pd.DataFrame({'feature': list(train_data_X),\n",
    "                                           'importance': gb_grid.best_estimator_.feature_importances_}).sort_values('importance', ascending=False)\n",
    "    features_top_n_gb = feature_imp_sorted_gb.head(top_n_features)['feature']\n",
    "    print('Sample 10 Feature from GB Classifier:')\n",
    "    print(str(features_top_n_gb[:10]))\n",
    "    \n",
    "    # DecisionTree\n",
    "    dt_est = DecisionTreeClassifier(random_state=0)\n",
    "    dt_param_grid = {'min_samples_split': [2, 4], 'max_depth': [20]}\n",
    "    dt_grid = model_selection.GridSearchCV(dt_est, dt_param_grid, n_jobs=25, cv=10, verbose=1)\n",
    "    dt_grid.fit(train_data_X, train_data_Y)\n",
    "    print('Top N Features Best DT Params:' + str(dt_grid.best_params_))\n",
    "    print('Top N Features Best DT Score:' + str(dt_grid.best_score_))\n",
    "    print('Top N Features DT Train Score:' + str(dt_grid.score(train_data_X, train_data_Y)))\n",
    "    feature_imp_sorted_dt = pd.DataFrame({'feature': list(train_data_X),\n",
    "                                          'importance': dt_grid.best_estimator_.feature_importances_}).sort_values('importance', ascending=False)\n",
    "    features_top_n_dt = feature_imp_sorted_dt.head(top_n_features)['feature']\n",
    "    print('Sample 10 Features from DT Classifier:')\n",
    "    print(str(features_top_n_dt[:10]))\n",
    "    \n",
    "    # merge the three models\n",
    "    features_top_n = pd.concat([features_top_n_rf, features_top_n_ada, features_top_n_et, features_top_n_gb, features_top_n_dt], \n",
    "                               ignore_index=True).drop_duplicates()\n",
    "    \n",
    "    features_importance = pd.concat([feature_imp_sorted_rf, feature_imp_sorted_ada, feature_imp_sorted_et, \n",
    "                                   feature_imp_sorted_gb, feature_imp_sorted_dt],ignore_index=True)\n",
    "    \n",
    "    return features_top_n , features_importance\n",
    "\n",
    "feature_to_pick = 50\n",
    "feature_top_n, feature_importance = get_top_n_features(df_train[features], df_train.y, feature_to_pick)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-397155b1",
   "language": "python",
   "display_name": "PyCharm (kesai)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}